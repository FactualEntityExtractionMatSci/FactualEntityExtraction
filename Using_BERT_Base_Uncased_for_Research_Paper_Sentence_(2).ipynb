{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Using_BERT_Base_Uncased_for_Research_Paper_Sentence (2).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8cd8503203044f9daec67bee1ae29938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ee4e557ca95a46e78a8678076f40d21b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5750f9116af7404cb8de690259acac79",
              "IPY_MODEL_6f2d2c81dd87418e9a8884bb438a3187"
            ]
          }
        },
        "ee4e557ca95a46e78a8678076f40d21b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5750f9116af7404cb8de690259acac79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4a866d6ccc074e2a88d701865a301a3d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_439399266bf446f0a406e0dcd254233c"
          }
        },
        "6f2d2c81dd87418e9a8884bb438a3187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_06684ad7e78446d99388be924a5dc9e7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 3.67MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_80a55c4cd7ba42fe9626481eef474b85"
          }
        },
        "4a866d6ccc074e2a88d701865a301a3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "439399266bf446f0a406e0dcd254233c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06684ad7e78446d99388be924a5dc9e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "80a55c4cd7ba42fe9626481eef474b85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f84f935a193f4dc28c8fe5efe892ce53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a4097ba35e304cf38e7c498e7ebabd90",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5751cb7b3f65427ba426838aeb4c28cd",
              "IPY_MODEL_8b375482d4c24fd39a8e36ea0876dc6c"
            ]
          }
        },
        "a4097ba35e304cf38e7c498e7ebabd90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5751cb7b3f65427ba426838aeb4c28cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_926aebab60624bee9ced127c8ff86431",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0bdc6e17b73b4c9089bf0b874876ecab"
          }
        },
        "8b375482d4c24fd39a8e36ea0876dc6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_98357e17dba74d6f90ea99d85b8b2d52",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:32&lt;00:00, 13.3B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b5448c141de74518b30df5efff64c51d"
          }
        },
        "926aebab60624bee9ced127c8ff86431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0bdc6e17b73b4c9089bf0b874876ecab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98357e17dba74d6f90ea99d85b8b2d52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b5448c141de74518b30df5efff64c51d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b78a4e258f444f21b6eb0b0149d0607b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c6effe76dfd74f72a20c4b1d30f57413",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e7f70674d9cd4e1189c203f266f23688",
              "IPY_MODEL_ead1c7ec6ce24a38a07195a9ae70e917"
            ]
          }
        },
        "c6effe76dfd74f72a20c4b1d30f57413": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7f70674d9cd4e1189c203f266f23688": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bec58fa152944fe094b195b2f6799638",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8fcf03258b784f81834086c0c762c435"
          }
        },
        "ead1c7ec6ce24a38a07195a9ae70e917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_439fa6ad2e9242a481abbd87fef45b0a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:07&lt;00:00, 57.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c0a1e789901f45e3b413aac513378bbe"
          }
        },
        "bec58fa152944fe094b195b2f6799638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8fcf03258b784f81834086c0c762c435": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "439fa6ad2e9242a481abbd87fef45b0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c0a1e789901f45e3b413aac513378bbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Js1Lt7xzp53p"
      },
      "source": [
        "# Using BERT-Base-Uncased for D-FJ and FactJudge"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjZ0kz1wqEk2"
      },
      "source": [
        "### Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rmv3qUboPtC"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "import csv\n",
        "import time\n",
        "import datetime\n",
        "import itertools\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2RtnGzFp4cb"
      },
      "source": [
        "### Checking if GPU available\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EaF0biAJqSVc",
        "outputId": "8d744379-400e-46f0-a7d9-c84a7ad48226"
      },
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'{torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVT6GHPmqvhM"
      },
      "source": [
        "### Downloading and Importing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmY3EHwDsyht",
        "outputId": "4ded0aa0-0760-41ad-e416-f729fb286d88"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQUYbKRUszEB"
      },
      "source": [
        "# mqpa_path = \"/content/gdrive/My Drive/MPQAYahoo/mpqa\"\n",
        "# yahoo_path = \"/content/gdrive/My Drive/MPQAYahoo/yahoo120\"\n",
        "\n",
        "# # Importing data from mqpa\n",
        "# mqpa_train_df = pd.DataFrame(columns=['Sentence', 'O/F', 'Label', 'Document No.'])\n",
        "# for i in trange(1, 536):\n",
        "#   new_df = pd.read_csv(f'{mqpa_path}/hits_{i}.csv').dropna()\n",
        "#   new_df['Document No.'] = i\n",
        "#   new_df['Label'] = new_df['O/F'].map({'o': 0, 'f': 1}).astype('int64')\n",
        "#   mqpa_train_df = pd.concat([mqpa_train_df, new_df])\n",
        "\n",
        "# yahoo_train_df = pd.DataFrame(columns=['Sentence', 'O/F', 'Label', 'Document No.'])\n",
        "# for i in trange(1, 121):\n",
        "#   new_df = pd.read_csv(f'{yahoo_path}/hits_{i}.csv').dropna()\n",
        "#   new_df['Document No.'] = i\n",
        "#   new_df['Label'] = new_df['O/F'].map({'o': 0, 'f': 1}).astype('int64')\n",
        "#   yahoo_test_df = pd.concat([yahoo_test_df, new_df])\n",
        "#   yahoo_train_df = pd.concat([yahoo_train_df, new_df])\n",
        "\n",
        "# mqpa_train_df['Collection'] = 'MQPA'\n",
        "# yahoo_train_df['Collection'] = 'Yahoo'\n",
        "\n",
        "# train_df = pd.concat([mqpa_train_df, yahoo_train_df])\n",
        "# train_df.sample(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "vXh3pS1u9H8L",
        "outputId": "f0d62c87-af49-45cb-9e75-8c6cc6afd671"
      },
      "source": [
        "sentences_df = pd.read_csv(\"/content/gdrive/My Drive/SentencesLabeling/labeled_sentences.csv\")\n",
        "sentences_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "      <th>Subcat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>We have investigated the electronic structure ...</td>\n",
              "      <td>1</td>\n",
              "      <td>METHOD|MATERIAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>It was found that the Sn valence states (5s, 5...</td>\n",
              "      <td>1</td>\n",
              "      <td>METHOD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>It was demonstrated that the metallic states a...</td>\n",
              "      <td>1</td>\n",
              "      <td>MATERIAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>We discuss the nature of the electronic states...</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ar X\\niv :1\\n10 7.</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>34 11\\nv1 [\\nco nd\\n-m at\\n.m tr\\nlsc\\ni] 1\\n8...</td>\n",
              "      <td>1</td>\n",
              "      <td>METHOD|MATERIAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Lukoyanovâˆ—,âˆ—âˆ—, E. Z.Kurmaevâˆ—, L.D.</td>\n",
              "      <td>0</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Finkelsteinâˆ—, A.Moewes+\\n+Department of Physic...</td>\n",
              "      <td>1</td>\n",
              "      <td>METHOD|MATERIAL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>It was found that the Sn valence states (5s, 5...</td>\n",
              "      <td>1</td>\n",
              "      <td>METHOD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>It was demonstrated that the metallic states a...</td>\n",
              "      <td>1</td>\n",
              "      <td>MATERIAL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Label           Subcat\n",
              "0  We have investigated the electronic structure ...      1  METHOD|MATERIAL\n",
              "1  It was found that the Sn valence states (5s, 5...      1           METHOD\n",
              "2  It was demonstrated that the metallic states a...      1         MATERIAL\n",
              "3  We discuss the nature of the electronic states...      0                O\n",
              "4                                 ar X\\niv :1\\n10 7.      0                O\n",
              "5  34 11\\nv1 [\\nco nd\\n-m at\\n.m tr\\nlsc\\ni] 1\\n8...      1  METHOD|MATERIAL\n",
              "6                 Lukoyanovâˆ—,âˆ—âˆ—, E. Z.Kurmaevâˆ—, L.D.      0                O\n",
              "7  Finkelsteinâˆ—, A.Moewes+\\n+Department of Physic...      1  METHOD|MATERIAL\n",
              "8  It was found that the Sn valence states (5s, 5...      1           METHOD\n",
              "9  It was demonstrated that the metallic states a...      1         MATERIAL"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6S-acDvwjqL"
      },
      "source": [
        "# len(sentences_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJzVoHsKwrJQ"
      },
      "source": [
        "sentences_df = sentences_df.dropna()\r\n",
        "# len([sentence for sentence in list(sentences_df[\"Sentence\"]) if sentence.startswith(\"b'\")])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxv_IMxPbAlg"
      },
      "source": [
        "# sentences_df[\"Label\"].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40uCzfV9ujse"
      },
      "source": [
        "### Importing BERT Model Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rjRgryxunRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ffc818-9118-4bb8-a8a0-b0844ffdfc1a"
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.9MB 18.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.2MB 51.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 57.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=cbf63af5d4ab8f18913fa8c8904ec08e17091dbee094cc267d6971187e2dae7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Q_t9WKacvU"
      },
      "source": [
        "### Importing sklearn requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqBl6bh8ab5U"
      },
      "source": [
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, precision_recall_curve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkVYOihYuaOq"
      },
      "source": [
        "### BERT Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oqMXPBluY9n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "8cd8503203044f9daec67bee1ae29938",
            "ee4e557ca95a46e78a8678076f40d21b",
            "5750f9116af7404cb8de690259acac79",
            "6f2d2c81dd87418e9a8884bb438a3187",
            "4a866d6ccc074e2a88d701865a301a3d",
            "439399266bf446f0a406e0dcd254233c",
            "06684ad7e78446d99388be924a5dc9e7",
            "80a55c4cd7ba42fe9626481eef474b85"
          ]
        },
        "outputId": "d3cec614-a93b-46b3-f8f8-8018d5d18bd6"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def preprocess_bert(data):\n",
        "  encoded = tokenizer.encode_plus(\n",
        "      text = data,\n",
        "      add_special_tokens = True,\n",
        "      max_length = MAX_LEN,\n",
        "      pad_to_max_length = True,\n",
        "      return_attention_mask = True,\n",
        "      truncation=True\n",
        "  )\n",
        "\n",
        "  return encoded.get('input_ids'), encoded.get('attention_mask')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8cd8503203044f9daec67bee1ae29938",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqZ-gF4kBHU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "123939a5-918a-4a7e-91e4-2c5d3c963139"
      },
      "source": [
        "all_sentences = list(sentences_df[\"Sentence\"])\n",
        "encoded_sents = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_sentences]\n",
        "plt.hist([len(sent) for sent in encoded_sents])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (568 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([4.308e+04, 3.611e+03, 3.530e+02, 1.220e+02, 3.700e+01, 9.000e+00,\n",
              "        2.000e+00, 4.000e+00, 1.000e+00, 2.000e+00]),\n",
              " array([  3. ,  60.6, 118.2, 175.8, 233.4, 291. , 348.6, 406.2, 463.8,\n",
              "        521.4, 579. ]),\n",
              " <a list of 10 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mW5GiVatkeNt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adea2a3d-9f7a-4c1d-c47c-fcaf578f74bb"
      },
      "source": [
        "MAX_LEN = 128\n",
        "sentences_df['input_ids'], sentences_df['attention_mask'] = zip(*sentences_df['Sentence'].apply(preprocess_bert))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2155: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4JqCeoUbaNj"
      },
      "source": [
        "### Separating preprocessed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bl8Gsf4dpzAC"
      },
      "source": [
        "# mqpa_group = mqpa_train_df.groupby('Document No.')\n",
        "# mqpa_inputids_document_wise = mqpa_group['input_ids'].apply(np.array)\n",
        "# mqpa_masks_document_wise = mqpa_group['attention_mask'].apply(np.array)\n",
        "# mqpa_ytrain_document_wise = mqpa_group['Label'].apply(np.array)\n",
        "\n",
        "# yahoo_group = yahoo_train_df.groupby('Document No.')\n",
        "# yahoo_inputids_document_wise = yahoo_group['input_ids'].apply(np.array)\n",
        "# yahoo_masks_document_wise = yahoo_group['attention_mask'].apply(np.array)\n",
        "# yahoo_ytrain_document_wise = yahoo_group['Label'].apply(np.array)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgwMxYsfbfzv"
      },
      "source": [
        "### Fixed Random State"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QbfXSlw7mSE"
      },
      "source": [
        "RANDOM_STATE = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-5SGYfbbjwI"
      },
      "source": [
        "### Creating the final model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKkHgO4G_I0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dab10ad-31fc-40cc-d9cd-f22c18fcd70e"
      },
      "source": [
        "%%time\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "  def __init__(self, freeze_bert=False, RNNLayer='RNN', activation='Sigmoid', hidden_nodes=50):\n",
        "    super(BertClassifier, self).__init__()\n",
        "\n",
        "    D_in, H, D_out = 768, hidden_nodes, 2\n",
        "    self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "    if RNNLayer == 'RNN':\n",
        "      self.rnn = nn.RNN(D_in, H, batch_first = True)\n",
        "    elif RNNLayer == 'LSTM':\n",
        "      self.rnn = nn.LSTM(D_in, H, batch_first = True)\n",
        "    self.linear = nn.Linear(D_in, D_out)\n",
        "    if activation == 'Sigmoid':\n",
        "      self.activation = nn.Sigmoid()\n",
        "    elif activation == 'ReLU':\n",
        "      self.activation = nn.ReLU()\n",
        "    elif activation == 'Tanh':\n",
        "      self.activation = nn.Tanh()\n",
        "\n",
        "    modules = [self.bert.embeddings, *self.bert.encoder.layer[:2]]\n",
        "    if freeze_bert:\n",
        "      for module in modules:\n",
        "        for param in module.parameters():\n",
        "          param.requires_grad = False\n",
        "  \n",
        "  def forward(self, input_ids, attention_masks):\n",
        "\n",
        "    outputs = self.bert(input_ids=input_ids, attention_mask=attention_masks)\n",
        "    last_hidden_state = outputs[0][:, 0, :]\n",
        "    # rnn_out, _ = self.rnn(last_hidden_state)\n",
        "    # activated = self.activation(rnn_out[:, -1, :])\n",
        "    # logits = self.linear(rnn_out[:, -1, :])\n",
        "    logits = self.linear(last_hidden_state)\n",
        "    return logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 26 Âµs, sys: 0 ns, total: 26 Âµs\n",
            "Wall time: 28.1 Âµs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ur67S-S2buGf"
      },
      "source": [
        "### Train Test k-fold splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU57AIi5GRmS"
      },
      "source": [
        "def KFoldIds(X_train, labels, k=5):\n",
        "  kf = StratifiedKFold(n_splits=k, random_state=RANDOM_STATE, shuffle=True)\n",
        "\n",
        "  train_test_splits = []\n",
        "  for train_index, test_index in kf.split(X_train, labels): # splitting in ratio of documents\n",
        "    # arrays containing arrays of sentences in each document\n",
        "    train_test_splits.append((train_index, test_index))\n",
        "  \n",
        "  return train_test_splits\n",
        "\n",
        "def create_train_test_datasets(input_ids, masks, labels, k=5):\n",
        "  input_ids_final = []\n",
        "  masks_final = []\n",
        "  labels_final = []\n",
        "  input_ids_final_test = []\n",
        "  masks_final_test = []\n",
        "  labels_final_test = []\n",
        "\n",
        "  train_test_splits = KFoldIds(input_ids, labels, k)\n",
        "  for train_index, test_index in train_test_splits:\n",
        "    input_ids_tr, input_ids_test = input_ids[train_index], input_ids[test_index]\n",
        "    masks_tr, masks_test = masks[train_index], masks[test_index]\n",
        "    labels_tr, labels_test = labels[train_index], labels[test_index]\n",
        "    # concatenate all arrays together for training purpose\n",
        "    input_ids_tensor = torch.tensor(list(input_ids_tr))\n",
        "    masks_tensor = torch.tensor(list(masks_tr))\n",
        "    labels_tensor = torch.tensor(list(labels_tr))\n",
        "    input_ids_tensor_test = torch.tensor(list(input_ids_test))\n",
        "    masks_tensor_test = torch.tensor(list(masks_test))\n",
        "    labels_tensor_test = torch.tensor(list(labels_test))\n",
        "    # store all the divided parts for reusing again and again\n",
        "    input_ids_final.append(input_ids_tensor)\n",
        "    masks_final.append(masks_tensor)\n",
        "    labels_final.append(labels_tensor)\n",
        "    input_ids_final_test.append(input_ids_tensor_test)\n",
        "    masks_final_test.append(masks_tensor_test)\n",
        "    labels_final_test.append(labels_tensor_test)\n",
        "  \n",
        "  return input_ids_final, masks_final, labels_final, input_ids_final_test, masks_final_test, labels_final_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRVjGpdEb7_9"
      },
      "source": [
        "## Model initializer and scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXuJg7QTwr6K"
      },
      "source": [
        "def initialize_model(RNNLayer='RNN', activation='Sigmoid'):\n",
        "  # Instantiate Bert Classifier\n",
        "  bert_classifier = BertClassifier(freeze_bert=True, RNNLayer=RNNLayer, activation=activation)\n",
        "\n",
        "  # Tell PyTorch to run the model on GPU\n",
        "  bert_classifier.to(device)\n",
        "\n",
        "  # Create the optimizer\n",
        "  optimizer = AdamW(bert_classifier.parameters(),\n",
        "                    lr=5e-5,    \n",
        "                    eps=1e-8   \n",
        "                    )\n",
        "  \n",
        "  return bert_classifier, optimizer\n",
        "\n",
        "def get_scheduler(train_dataloader, optimizer, epochs=4):\n",
        "  # Total number of training steps\n",
        "  total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "  # Set up the learning rate scheduler\n",
        "  scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                              num_warmup_steps=0, \n",
        "                                              num_training_steps=total_steps)\n",
        "  return scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUZC4Go6cF0X"
      },
      "source": [
        "### Training method for a combination of hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISs6NEeK19dl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f41d0448-58a3-404c-9fa3-c23332d0ded6"
      },
      "source": [
        "%%time\n",
        "\n",
        "def train(model, train_dataloader, optimizer, scheduler, epochs=4, test_ids = None, test_masks = None, test_labels = None):\n",
        "  print(\"Start training...\")\n",
        "  # loss_fn = nn.BCELoss()\n",
        "  loss_fn=nn.CrossEntropyLoss()\n",
        "  for epoch_i in range(epochs):\n",
        "    print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Elapsed':^9}\")\n",
        "    print('-'*50)\n",
        "\n",
        "    t0_epoch, t0_batch = time.time(), time.time()\n",
        "    total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "    # Put the model into the training mode\n",
        "    model.train()\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "      batch_counts +=1\n",
        "      # Load batch to GPU\n",
        "      b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "      # Zero out any previously calculated gradients\n",
        "      model.zero_grad()\n",
        "\n",
        "      # Perform a forward pass. This will return logits.\n",
        "      logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "      # Compute loss and accumulate the loss values\n",
        "      # loss = loss_fn(logits, b_labels.to(torch.float32).unsqueeze(1))\n",
        "      loss = loss_fn(logits, b_labels)\n",
        "      batch_loss += loss.item()\n",
        "      total_loss += loss.item()\n",
        "\n",
        "      # Perform a backward pass to calculate gradients\n",
        "      loss.backward()\n",
        "\n",
        "      # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      # Update parameters and the learning rate\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "        # Calculate time elapsed for 20 batches\n",
        "        time_elapsed = time.time() - t0_batch\n",
        "\n",
        "        # Print training results\n",
        "        print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "        # Reset batch tracking variables\n",
        "        batch_loss, batch_counts = 0, 0\n",
        "        t0_batch = time.time()\n",
        "      \n",
        "    all_probs = bert_predict(model, test_ids, test_masks, test_labels)\n",
        "    all_probs = F.softmax(torch.cat(all_probs), dim=1).cpu().numpy()\n",
        "    precision, recall, thresholds = precision_recall_curve(np.array(test_labels), all_probs[:, 1])\n",
        "    fscore = (2 * precision * recall) / (precision + recall)\n",
        "    ix = np.nanargmax(fscore)\n",
        "    accuracy = accuracy_score(np.array(test_labels), np.where(all_probs[:,1]>=thresholds[ix], 1, 0))\n",
        "\n",
        "    csv_file = open('/content/gdrive/My Drive/SentencesLabeling/freeze_bert_2_32.csv', mode='a')\n",
        "    csv_write = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "    csv_write.writerow([epoch_i, precision[ix], recall[ix], accuracy, thresholds[ix]])\n",
        "    csv_file.close()\n",
        "    \n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    print(f'Average Train Loss: {avg_train_loss}')\n",
        "\n",
        "    # Printing results for these hyperparameters\n",
        "    print(f\"{'Epochs':^10} | {'Precision':^15} | {'Recall':^15} | {'Accuracy':^15} | {'Threshold':^15}\")\n",
        "\n",
        "    print(f\"{epoch_i:^10} | {precision[ix]:^15.2f} | {recall[ix]:^15.2f} | {accuracy:^15.2f} | {thresholds[ix]:^15.2f}\")\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 Âµs, sys: 0 ns, total: 4 Âµs\n",
            "Wall time: 5.96 Âµs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSnIqYUgKOgv"
      },
      "source": [
        "def set_seed(seed_value=42):\n",
        "  \"\"\"Set seed for reproducibility.\n",
        "  \"\"\"\n",
        "  random.seed(seed_value)\n",
        "  np.random.seed(seed_value)\n",
        "  torch.manual_seed(seed_value)\n",
        "  torch.cuda.manual_seed_all(seed_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5w0SIXZcOkn"
      },
      "source": [
        "### Predict with trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MxRj83YMMHk"
      },
      "source": [
        "def bert_predict(model, input_ids, masks, labels):\n",
        "  test_data = TensorDataset(input_ids, masks, labels)\n",
        "  test_sampler = SequentialSampler(test_data)\n",
        "  test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=32)\n",
        "\n",
        "\n",
        "  all_probs=[]\n",
        "  for batch in test_dataloader:\n",
        "    # Load batch to GPU\n",
        "    b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
        "\n",
        "    # Compute logits\n",
        "    with torch.no_grad():\n",
        "      probs = model(b_input_ids, b_attn_mask)\n",
        "    all_probs.append(probs)\n",
        "\n",
        "  return all_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVL6nQuOYwFF"
      },
      "source": [
        "def train_loop():\n",
        "  \n",
        "  k = 5\n",
        "\n",
        "  input_ids_final, masks_final, labels_final, \\\n",
        "    input_ids_final_test, masks_final_test, labels_final_test = \\\n",
        "    create_train_test_datasets(np.array(sentences_df[\"input_ids\"]), np.array(sentences_df[\"attention_mask\"]), np.array(sentences_df[\"Label\"]))\n",
        "\n",
        "  RNNLayers = ['LSTM']\n",
        "  batch_sizes = [32]\n",
        "  epochs_s = [10]\n",
        "  activations = ['Sigmoid']\n",
        "\n",
        "  for RNNLayer, batch_size, epochs, activation in list(itertools.product(RNNLayers, batch_sizes, epochs_s, activations)):\n",
        "\n",
        "    time0 = time.time()\n",
        "\n",
        "    print(f\"{'Model':^7} | {'Activation':^15} {'Batch Size':^15} | {'Epochs':^10}\")\n",
        "    print(f\"{RNNLayer:^7} | {activation:^15} {batch_size:^15} | {epochs:^10}\")\n",
        "\n",
        "    for i in range(1, k):\n",
        "\n",
        "      train_data = TensorDataset(input_ids_final[i], masks_final[i], labels_final[i])\n",
        "      train_sampler = RandomSampler(train_data)\n",
        "      train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "      bert_classifier, optimizer = initialize_model(RNNLayer=RNNLayer, activation=activation)\n",
        "      scheduler = get_scheduler(train_dataloader, optimizer, epochs=epochs)\n",
        "      model = train(bert_classifier, train_dataloader, optimizer, scheduler, epochs, \n",
        "                    input_ids_final_test[i], masks_final_test[i], labels_final_test[i])\n",
        "\n",
        "    time_end = time.time()\n",
        "\n",
        "    train_time = datetime.timedelta(seconds=time_end-time0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDcLFRCvdKFE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f84f935a193f4dc28c8fe5efe892ce53",
            "a4097ba35e304cf38e7c498e7ebabd90",
            "5751cb7b3f65427ba426838aeb4c28cd",
            "8b375482d4c24fd39a8e36ea0876dc6c",
            "926aebab60624bee9ced127c8ff86431",
            "0bdc6e17b73b4c9089bf0b874876ecab",
            "98357e17dba74d6f90ea99d85b8b2d52",
            "b5448c141de74518b30df5efff64c51d",
            "b78a4e258f444f21b6eb0b0149d0607b",
            "c6effe76dfd74f72a20c4b1d30f57413",
            "e7f70674d9cd4e1189c203f266f23688",
            "ead1c7ec6ce24a38a07195a9ae70e917",
            "bec58fa152944fe094b195b2f6799638",
            "8fcf03258b784f81834086c0c762c435",
            "439fa6ad2e9242a481abbd87fef45b0a",
            "c0a1e789901f45e3b413aac513378bbe"
          ]
        },
        "outputId": "dedbe299-dd18-4e7d-e544-6259915152a9"
      },
      "source": [
        "set_seed(42)\n",
        "train_loop()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Model  |   Activation      Batch Size    |   Epochs  \n",
            " LSTM   |     Sigmoid           32        |     10    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f84f935a193f4dc28c8fe5efe892ce53",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b78a4e258f444f21b6eb0b0149d0607b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start training...\n",
            " Epoch  |  Batch  |  Train Loss  |  Elapsed \n",
            "--------------------------------------------------\n",
            "   1    |   20    |   0.574110   |   11.86  \n",
            "   1    |   40    |   0.457225   |   11.52  \n",
            "   1    |   60    |   0.431397   |   11.71  \n",
            "   1    |   80    |   0.417954   |   12.06  \n",
            "   1    |   100   |   0.377764   |   12.49  \n",
            "   1    |   120   |   0.347607   |   12.48  \n",
            "   1    |   140   |   0.315710   |   12.10  \n",
            "   1    |   160   |   0.330451   |   11.91  \n",
            "   1    |   180   |   0.322236   |   11.86  \n",
            "   1    |   200   |   0.243194   |   11.95  \n",
            "   1    |   220   |   0.253026   |   12.14  \n",
            "   1    |   240   |   0.241429   |   12.19  \n",
            "   1    |   260   |   0.265849   |   12.20  \n",
            "   1    |   280   |   0.226242   |   12.14  \n",
            "   1    |   300   |   0.250268   |   12.06  \n",
            "   1    |   320   |   0.172867   |   12.01  \n",
            "   1    |   340   |   0.168260   |   12.03  \n",
            "   1    |   360   |   0.229025   |   12.09  \n",
            "   1    |   380   |   0.193717   |   12.08  \n",
            "   1    |   400   |   0.189433   |   12.10  \n",
            "   1    |   420   |   0.170900   |   12.14  \n",
            "   1    |   440   |   0.167037   |   12.15  \n",
            "   1    |   460   |   0.186027   |   12.16  \n",
            "   1    |   480   |   0.167770   |   12.13  \n",
            "   1    |   500   |   0.146514   |   12.13  \n",
            "   1    |   520   |   0.151794   |   12.13  \n",
            "   1    |   540   |   0.169238   |   12.11  \n",
            "   1    |   560   |   0.131016   |   12.06  \n",
            "   1    |   580   |   0.148774   |   12.07  \n",
            "   1    |   600   |   0.172512   |   12.13  \n",
            "   1    |   620   |   0.136916   |   12.10  \n",
            "   1    |   640   |   0.130060   |   12.07  \n",
            "   1    |   660   |   0.129789   |   12.07  \n",
            "   1    |   680   |   0.140642   |   12.07  \n",
            "   1    |   700   |   0.133596   |   12.10  \n",
            "   1    |   720   |   0.098091   |   12.04  \n",
            "   1    |   740   |   0.109657   |   12.04  \n",
            "   1    |   760   |   0.091511   |   12.08  \n",
            "   1    |   780   |   0.138297   |   12.07  \n",
            "   1    |   800   |   0.087830   |   12.09  \n",
            "   1    |   820   |   0.113494   |   12.13  \n",
            "   1    |   840   |   0.109539   |   12.13  \n",
            "   1    |   860   |   0.123802   |   12.08  \n",
            "   1    |   880   |   0.097764   |   12.08  \n",
            "   1    |   900   |   0.078663   |   12.10  \n",
            "   1    |   920   |   0.113801   |   12.10  \n",
            "   1    |   940   |   0.090497   |   12.11  \n",
            "   1    |   960   |   0.080205   |   12.08  \n",
            "   1    |   980   |   0.106572   |   12.10  \n",
            "   1    |  1000   |   0.089025   |   12.11  \n",
            "   1    |  1020   |   0.109215   |   12.12  \n",
            "   1    |  1040   |   0.090401   |   12.09  \n",
            "   1    |  1060   |   0.076951   |   12.10  \n",
            "   1    |  1080   |   0.123156   |   12.09  \n",
            "   1    |  1100   |   0.128541   |   12.08  \n",
            "   1    |  1120   |   0.068610   |   12.04  \n",
            "   1    |  1140   |   0.067512   |   12.06  \n",
            "   1    |  1160   |   0.089845   |   12.10  \n",
            "   1    |  1180   |   0.066036   |   11.80  \n",
            "Average Train Loss: 0.1806616145868255\n",
            "  Epochs   |    Precision    |     Recall      |    Accuracy     |    Threshold   \n",
            "    0      |      0.97       |      0.95       |      0.98       |      0.25      \n",
            " Epoch  |  Batch  |  Train Loss  |  Elapsed \n",
            "--------------------------------------------------\n",
            "   2    |   20    |   0.046276   |   12.58  \n",
            "   2    |   40    |   0.045581   |   12.05  \n",
            "   2    |   60    |   0.063392   |   12.02  \n",
            "   2    |   80    |   0.047222   |   12.06  \n",
            "   2    |   100   |   0.073534   |   12.06  \n",
            "   2    |   120   |   0.087255   |   12.08  \n",
            "   2    |   140   |   0.078668   |   12.05  \n",
            "   2    |   160   |   0.070906   |   12.04  \n",
            "   2    |   180   |   0.075138   |   12.07  \n",
            "   2    |   200   |   0.041772   |   12.04  \n",
            "   2    |   220   |   0.046422   |   12.06  \n",
            "   2    |   240   |   0.104889   |   12.05  \n",
            "   2    |   260   |   0.053114   |   12.05  \n",
            "   2    |   280   |   0.111820   |   12.05  \n",
            "   2    |   300   |   0.069826   |   12.02  \n",
            "   2    |   320   |   0.054988   |   12.02  \n",
            "   2    |   340   |   0.046971   |   12.02  \n",
            "   2    |   360   |   0.080952   |   12.04  \n",
            "   2    |   380   |   0.049280   |   12.06  \n",
            "   2    |   400   |   0.063130   |   12.07  \n",
            "   2    |   420   |   0.034724   |   12.07  \n",
            "   2    |   440   |   0.054588   |   12.07  \n",
            "   2    |   460   |   0.038539   |   12.09  \n",
            "   2    |   480   |   0.059735   |   12.08  \n",
            "   2    |   500   |   0.021447   |   12.08  \n",
            "   2    |   520   |   0.080721   |   12.13  \n",
            "   2    |   540   |   0.084193   |   12.08  \n",
            "   2    |   560   |   0.068540   |   12.08  \n",
            "   2    |   580   |   0.060056   |   12.07  \n",
            "   2    |   600   |   0.049674   |   12.06  \n",
            "   2    |   620   |   0.071049   |   12.08  \n",
            "   2    |   640   |   0.042680   |   12.03  \n",
            "   2    |   660   |   0.049476   |   12.05  \n",
            "   2    |   680   |   0.042561   |   12.07  \n",
            "   2    |   700   |   0.077415   |   12.07  \n",
            "   2    |   720   |   0.083785   |   12.08  \n",
            "   2    |   740   |   0.073228   |   12.07  \n",
            "   2    |   760   |   0.049527   |   12.05  \n",
            "   2    |   780   |   0.053432   |   12.05  \n",
            "   2    |   800   |   0.036304   |   12.06  \n",
            "   2    |   820   |   0.033075   |   12.03  \n",
            "   2    |   840   |   0.057740   |   12.02  \n",
            "   2    |   860   |   0.072068   |   12.07  \n",
            "   2    |   880   |   0.047629   |   12.05  \n",
            "   2    |   900   |   0.075194   |   12.06  \n",
            "   2    |   920   |   0.031621   |   12.05  \n",
            "   2    |   940   |   0.040813   |   12.08  \n",
            "   2    |   960   |   0.083426   |   12.08  \n",
            "   2    |   980   |   0.056780   |   12.10  \n",
            "   2    |  1000   |   0.070776   |   12.07  \n",
            "   2    |  1020   |   0.042306   |   12.09  \n",
            "   2    |  1040   |   0.036696   |   12.07  \n",
            "   2    |  1060   |   0.050880   |   12.08  \n",
            "   2    |  1080   |   0.042731   |   12.09  \n",
            "   2    |  1100   |   0.048822   |   12.08  \n",
            "   2    |  1120   |   0.064072   |   12.09  \n",
            "   2    |  1140   |   0.076697   |   12.08  \n",
            "   2    |  1160   |   0.057238   |   12.10  \n",
            "   2    |  1180   |   0.054852   |   11.79  \n",
            "Average Train Loss: 0.05907773187755237\n",
            "  Epochs   |    Precision    |     Recall      |    Accuracy     |    Threshold   \n",
            "    1      |      0.98       |      0.96       |      0.98       |      0.55      \n",
            " Epoch  |  Batch  |  Train Loss  |  Elapsed \n",
            "--------------------------------------------------\n",
            "   3    |   20    |   0.019116   |   12.60  \n",
            "   3    |   40    |   0.021977   |   12.02  \n",
            "   3    |   60    |   0.055839   |   12.04  \n",
            "   3    |   80    |   0.026599   |   12.02  \n",
            "   3    |   100   |   0.031795   |   12.05  \n",
            "   3    |   120   |   0.045424   |   12.06  \n",
            "   3    |   140   |   0.015369   |   12.03  \n",
            "   3    |   160   |   0.029014   |   12.07  \n",
            "   3    |   180   |   0.026925   |   12.06  \n",
            "   3    |   200   |   0.018269   |   12.06  \n",
            "   3    |   220   |   0.039827   |   12.08  \n",
            "   3    |   240   |   0.028948   |   12.06  \n",
            "   3    |   260   |   0.040591   |   12.07  \n",
            "   3    |   280   |   0.062652   |   12.07  \n",
            "   3    |   300   |   0.035655   |   12.05  \n",
            "   3    |   320   |   0.030752   |   12.07  \n",
            "   3    |   340   |   0.012860   |   12.04  \n",
            "   3    |   360   |   0.035272   |   12.05  \n",
            "   3    |   380   |   0.032883   |   12.06  \n",
            "   3    |   400   |   0.012535   |   12.03  \n",
            "   3    |   420   |   0.033709   |   12.02  \n",
            "   3    |   440   |   0.016338   |   12.00  \n",
            "   3    |   460   |   0.046990   |   12.03  \n",
            "   3    |   480   |   0.003968   |   11.98  \n",
            "   3    |   500   |   0.010675   |   11.98  \n",
            "   3    |   520   |   0.024948   |   11.99  \n",
            "   3    |   540   |   0.050914   |   12.02  \n",
            "   3    |   560   |   0.028849   |   12.03  \n",
            "   3    |   580   |   0.029140   |   12.01  \n",
            "   3    |   600   |   0.047003   |   12.05  \n",
            "   3    |   620   |   0.042164   |   12.06  \n",
            "   3    |   640   |   0.022262   |   12.03  \n",
            "   3    |   660   |   0.037921   |   12.04  \n",
            "   3    |   680   |   0.023683   |   12.07  \n",
            "   3    |   700   |   0.035850   |   12.05  \n",
            "   3    |   720   |   0.015787   |   12.06  \n",
            "   3    |   740   |   0.025859   |   12.07  \n",
            "   3    |   760   |   0.026694   |   12.06  \n",
            "   3    |   780   |   0.045852   |   12.07  \n",
            "   3    |   800   |   0.034238   |   12.05  \n",
            "   3    |   820   |   0.027776   |   12.08  \n",
            "   3    |   840   |   0.016412   |   12.08  \n",
            "   3    |   860   |   0.045744   |   12.07  \n",
            "   3    |   880   |   0.033746   |   12.04  \n",
            "   3    |   900   |   0.026887   |   12.05  \n",
            "   3    |   920   |   0.048792   |   12.03  \n",
            "   3    |   940   |   0.042378   |   11.97  \n",
            "   3    |   960   |   0.026735   |   12.04  \n",
            "   3    |   980   |   0.043928   |   12.01  \n",
            "   3    |  1000   |   0.042844   |   12.04  \n",
            "   3    |  1020   |   0.046687   |   12.02  \n",
            "   3    |  1040   |   0.032434   |   12.04  \n",
            "   3    |  1060   |   0.043745   |   12.05  \n",
            "   3    |  1080   |   0.026707   |   12.03  \n",
            "   3    |  1100   |   0.066024   |   12.05  \n",
            "   3    |  1120   |   0.022319   |   12.06  \n",
            "   3    |  1140   |   0.006660   |   12.06  \n",
            "   3    |  1160   |   0.028094   |   12.05  \n",
            "   3    |  1180   |   0.056632   |   11.81  \n",
            "Average Train Loss: 0.032356372459894214\n",
            "  Epochs   |    Precision    |     Recall      |    Accuracy     |    Threshold   \n",
            "    2      |      0.98       |      0.97       |      0.98       |      0.94      \n",
            " Epoch  |  Batch  |  Train Loss  |  Elapsed \n",
            "--------------------------------------------------\n",
            "   4    |   20    |   0.008675   |   12.69  \n",
            "   4    |   40    |   0.031858   |   12.08  \n",
            "   4    |   60    |   0.018186   |   12.09  \n",
            "   4    |   80    |   0.020598   |   12.07  \n",
            "   4    |   100   |   0.017911   |   12.07  \n",
            "   4    |   120   |   0.037363   |   12.06  \n",
            "   4    |   140   |   0.014619   |   12.05  \n",
            "   4    |   160   |   0.001974   |   12.02  \n",
            "   4    |   180   |   0.010539   |   12.02  \n",
            "   4    |   200   |   0.008595   |   12.02  \n",
            "   4    |   220   |   0.004587   |   12.03  \n",
            "   4    |   240   |   0.001972   |   12.01  \n",
            "   4    |   260   |   0.001711   |   12.00  \n",
            "   4    |   280   |   0.003499   |   12.03  \n",
            "   4    |   300   |   0.000223   |   12.04  \n",
            "   4    |   320   |   0.031074   |   12.04  \n",
            "   4    |   340   |   0.001057   |   12.05  \n",
            "   4    |   360   |   0.016894   |   12.05  \n",
            "   4    |   380   |   0.010112   |   12.05  \n",
            "   4    |   400   |   0.030774   |   12.06  \n",
            "   4    |   420   |   0.024423   |   12.06  \n",
            "   4    |   440   |   0.024845   |   12.06  \n",
            "   4    |   460   |   0.004331   |   12.04  \n",
            "   4    |   480   |   0.022342   |   12.07  \n",
            "   4    |   500   |   0.022267   |   12.06  \n",
            "   4    |   520   |   0.015024   |   12.09  \n",
            "   4    |   540   |   0.010284   |   12.07  \n",
            "   4    |   560   |   0.011410   |   12.07  \n",
            "   4    |   580   |   0.014507   |   12.09  \n",
            "   4    |   600   |   0.001218   |   12.08  \n",
            "   4    |   620   |   0.023839   |   12.05  \n",
            "   4    |   640   |   0.011726   |   12.09  \n",
            "   4    |   660   |   0.004330   |   12.05  \n",
            "   4    |   680   |   0.009974   |   12.01  \n",
            "   4    |   700   |   0.021760   |   12.03  \n",
            "   4    |   720   |   0.021964   |   12.04  \n",
            "   4    |   740   |   0.024083   |   12.02  \n",
            "   4    |   760   |   0.006869   |   12.02  \n",
            "   4    |   780   |   0.020210   |   12.02  \n",
            "   4    |   800   |   0.003340   |   11.99  \n",
            "   4    |   820   |   0.003705   |   12.00  \n",
            "   4    |   840   |   0.030708   |   12.00  \n",
            "   4    |   860   |   0.004180   |   12.00  \n",
            "   4    |   880   |   0.014216   |   12.05  \n",
            "   4    |   900   |   0.000559   |   12.02  \n",
            "   4    |   920   |   0.029833   |   12.03  \n",
            "   4    |   940   |   0.023775   |   12.06  \n",
            "   4    |   960   |   0.027454   |   12.07  \n",
            "   4    |   980   |   0.018030   |   12.03  \n",
            "   4    |  1000   |   0.022402   |   12.07  \n",
            "   4    |  1020   |   0.011715   |   12.06  \n",
            "   4    |  1040   |   0.009849   |   12.06  \n",
            "   4    |  1060   |   0.013421   |   12.09  \n",
            "   4    |  1080   |   0.038624   |   12.10  \n",
            "   4    |  1100   |   0.031329   |   12.10  \n",
            "   4    |  1120   |   0.003186   |   12.08  \n",
            "   4    |  1140   |   0.035405   |   12.04  \n",
            "   4    |  1160   |   0.018681   |   12.04  \n",
            "   4    |  1180   |   0.012453   |   11.77  \n",
            "Average Train Loss: 0.015595739061863628\n",
            "  Epochs   |    Precision    |     Recall      |    Accuracy     |    Threshold   \n",
            "    3      |      0.98       |      0.98       |      0.99       |      0.27      \n",
            " Epoch  |  Batch  |  Train Loss  |  Elapsed \n",
            "--------------------------------------------------\n",
            "   5    |   20    |   0.003803   |   12.63  \n",
            "   5    |   40    |   0.004727   |   12.01  \n",
            "   5    |   60    |   0.005181   |   12.03  \n",
            "   5    |   80    |   0.008057   |   12.03  \n",
            "   5    |   100   |   0.000204   |   12.03  \n",
            "   5    |   120   |   0.000719   |   12.06  \n",
            "   5    |   140   |   0.015410   |   12.07  \n",
            "   5    |   160   |   0.007557   |   12.08  \n",
            "   5    |   180   |   0.005595   |   12.11  \n",
            "   5    |   200   |   0.000548   |   12.06  \n",
            "   5    |   220   |   0.005904   |   12.07  \n",
            "   5    |   240   |   0.003354   |   12.06  \n",
            "   5    |   260   |   0.000285   |   12.07  \n",
            "   5    |   280   |   0.029271   |   12.05  \n",
            "   5    |   300   |   0.000477   |   12.06  \n",
            "   5    |   320   |   0.025628   |   12.07  \n",
            "   5    |   340   |   0.003343   |   12.04  \n",
            "   5    |   360   |   0.019332   |   12.05  \n",
            "   5    |   380   |   0.003856   |   12.01  \n",
            "   5    |   400   |   0.013353   |   12.05  \n",
            "   5    |   420   |   0.009002   |   12.06  \n",
            "   5    |   440   |   0.004513   |   12.03  \n",
            "   5    |   460   |   0.001553   |   12.02  \n",
            "   5    |   480   |   0.017237   |   12.04  \n",
            "   5    |   500   |   0.008640   |   12.04  \n",
            "   5    |   520   |   0.008066   |   12.04  \n",
            "   5    |   540   |   0.013853   |   12.01  \n",
            "   5    |   560   |   0.000996   |   12.04  \n",
            "   5    |   580   |   0.001779   |   12.04  \n",
            "   5    |   600   |   0.001858   |   12.00  \n",
            "   5    |   620   |   0.012255   |   12.00  \n",
            "   5    |   640   |   0.017137   |   12.04  \n",
            "   5    |   660   |   0.007473   |   11.99  \n",
            "   5    |   680   |   0.036966   |   12.02  \n",
            "   5    |   700   |   0.008790   |   12.02  \n",
            "   5    |   720   |   0.013269   |   12.01  \n",
            "   5    |   740   |   0.000729   |   12.05  \n",
            "   5    |   760   |   0.016954   |   12.08  \n",
            "   5    |   780   |   0.002433   |   12.05  \n",
            "   5    |   800   |   0.001270   |   12.06  \n",
            "   5    |   820   |   0.023054   |   12.05  \n",
            "   5    |   840   |   0.021153   |   12.07  \n",
            "   5    |   860   |   0.024544   |   12.05  \n",
            "   5    |   880   |   0.012714   |   12.06  \n",
            "   5    |   900   |   0.007988   |   12.02  \n",
            "   5    |   920   |   0.008539   |   12.06  \n",
            "   5    |   940   |   0.007827   |   12.02  \n",
            "   5    |   960   |   0.011376   |   11.99  \n",
            "   5    |   980   |   0.009539   |   12.01  \n",
            "   5    |  1000   |   0.021563   |   12.00  \n",
            "   5    |  1020   |   0.000841   |   11.99  \n",
            "   5    |  1040   |   0.027653   |   12.00  \n",
            "   5    |  1060   |   0.001167   |   11.99  \n",
            "   5    |  1080   |   0.011015   |   12.00  \n",
            "   5    |  1100   |   0.012105   |   12.01  \n",
            "   5    |  1120   |   0.004023   |   12.00  \n",
            "   5    |  1140   |   0.028095   |   12.01  \n",
            "   5    |  1160   |   0.009145   |   12.00  \n",
            "   5    |  1180   |   0.023868   |   11.77  \n",
            "Average Train Loss: 0.010292602538305134\n",
            "  Epochs   |    Precision    |     Recall      |    Accuracy     |    Threshold   \n",
            "    4      |      0.99       |      0.96       |      0.99       |      0.83      \n",
            " Epoch  |  Batch  |  Train Loss  |  Elapsed \n",
            "--------------------------------------------------\n",
            "   6    |   20    |   0.000462   |   12.66  \n",
            "   6    |   40    |   0.014209   |   12.08  \n",
            "   6    |   60    |   0.002016   |   12.10  \n",
            "   6    |   80    |   0.005761   |   12.11  \n",
            "   6    |   100   |   0.011826   |   12.04  \n",
            "   6    |   120   |   0.000594   |   12.03  \n",
            "   6    |   140   |   0.005086   |   12.03  \n",
            "   6    |   160   |   0.023959   |   12.03  \n",
            "   6    |   180   |   0.010586   |   12.03  \n",
            "   6    |   200   |   0.008526   |   12.03  \n",
            "   6    |   220   |   0.001286   |   12.06  \n",
            "   6    |   240   |   0.001312   |   12.04  \n",
            "   6    |   260   |   0.000956   |   12.07  \n",
            "   6    |   280   |   0.003525   |   12.06  \n",
            "   6    |   300   |   0.012497   |   12.06  \n",
            "   6    |   320   |   0.007705   |   12.05  \n",
            "   6    |   340   |   0.010148   |   12.07  \n",
            "   6    |   360   |   0.000954   |   12.07  \n",
            "   6    |   380   |   0.005642   |   12.03  \n",
            "   6    |   400   |   0.003248   |   12.03  \n",
            "   6    |   420   |   0.002485   |   12.02  \n",
            "   6    |   440   |   0.000223   |   12.04  \n",
            "   6    |   460   |   0.042997   |   12.05  \n",
            "   6    |   480   |   0.017800   |   12.06  \n",
            "   6    |   500   |   0.008006   |   12.02  \n",
            "   6    |   520   |   0.000383   |   12.03  \n",
            "   6    |   540   |   0.011211   |   12.02  \n",
            "   6    |   560   |   0.020018   |   12.04  \n",
            "   6    |   580   |   0.012155   |   12.04  \n",
            "   6    |   600   |   0.009876   |   12.03  \n",
            "   6    |   620   |   0.000464   |   12.02  \n",
            "   6    |   640   |   0.000525   |   12.02  \n",
            "   6    |   660   |   0.000169   |   12.02  \n",
            "   6    |   680   |   0.003572   |   12.04  \n",
            "   6    |   700   |   0.000487   |   12.00  \n",
            "   6    |   720   |   0.000106   |   12.00  \n",
            "   6    |   740   |   0.005510   |   12.00  \n",
            "   6    |   760   |   0.007374   |   12.04  \n",
            "   6    |   780   |   0.009947   |   11.98  \n",
            "   6    |   800   |   0.000525   |   11.99  \n",
            "   6    |   820   |   0.010627   |   12.01  \n",
            "   6    |   840   |   0.005844   |   11.98  \n",
            "   6    |   860   |   0.009842   |   11.99  \n",
            "   6    |   880   |   0.006047   |   11.99  \n",
            "   6    |   900   |   0.004093   |   12.00  \n",
            "   6    |   920   |   0.020612   |   12.00  \n",
            "   6    |   940   |   0.001796   |   11.98  \n",
            "   6    |   960   |   0.000170   |   12.00  \n",
            "   6    |   980   |   0.000156   |   12.00  \n",
            "   6    |  1000   |   0.004085   |   11.98  \n",
            "   6    |  1020   |   0.008529   |   11.99  \n",
            "   6    |  1040   |   0.007022   |   12.00  \n",
            "   6    |  1060   |   0.015091   |   12.00  \n",
            "   6    |  1080   |   0.006568   |   11.99  \n",
            "   6    |  1100   |   0.015266   |   12.00  \n",
            "   6    |  1120   |   0.000646   |   11.99  \n",
            "   6    |  1140   |   0.015480   |   12.04  \n",
            "   6    |  1160   |   0.022177   |   12.04  \n",
            "   6    |  1180   |   0.000274   |   11.78  \n",
            "Average Train Loss: 0.007425490281655693\n",
            "  Epochs   |    Precision    |     Recall      |    Accuracy     |    Threshold   \n",
            "    5      |      0.98       |      0.97       |      0.99       |      0.91      \n",
            " Epoch  |  Batch  |  Train Loss  |  Elapsed \n",
            "--------------------------------------------------\n",
            "   7    |   20    |   0.005275   |   12.68  \n",
            "   7    |   40    |   0.000299   |   12.07  \n",
            "   7    |   60    |   0.007107   |   12.06  \n",
            "   7    |   80    |   0.006194   |   12.07  \n",
            "   7    |   100   |   0.013369   |   12.07  \n",
            "   7    |   120   |   0.022166   |   12.07  \n",
            "   7    |   140   |   0.000205   |   12.05  \n",
            "   7    |   160   |   0.000859   |   12.06  \n",
            "   7    |   180   |   0.008679   |   12.05  \n",
            "   7    |   200   |   0.000999   |   12.06  \n",
            "   7    |   220   |   0.005393   |   12.02  \n",
            "   7    |   240   |   0.000349   |   11.99  \n",
            "   7    |   260   |   0.000196   |   12.00  \n",
            "   7    |   280   |   0.000097   |   12.02  \n",
            "   7    |   300   |   0.001978   |   11.98  \n",
            "   7    |   320   |   0.000147   |   12.01  \n",
            "   7    |   340   |   0.006308   |   12.00  \n",
            "   7    |   360   |   0.000084   |   11.99  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pdvUlAVlNYI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}